{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840c21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid  # unique identifier\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cb11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42835ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    img = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    if ret:\n",
    "        cv.imshow('frame', img)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23c5a7",
   "metadata": {},
   "source": [
    "### Importing Yolo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0ccce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adilbhatti/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-1-9 Python-3.9.12 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/adilbhatti/anaconda3/lib/python3.9/site-packages/ipython-8.3.0.dist-info/METADATA'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ba829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    results = model(frame)\n",
    "    if ret:\n",
    "        cv.imshow('Yolo', np.squeeze(results.render()))\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ea527",
   "metadata": {},
   "source": [
    "### Training From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d092c7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b68e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2845c7",
   "metadata": {},
   "source": [
    "### COLLECTING IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b7e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for awake\n",
      "0 data/images/awake.5262d9f2-8811-11ed-ba42-321afeab1349.jpg\n",
      "1 data/images/awake.5304b056-8811-11ed-ba42-321afeab1349.jpg\n",
      "2 data/images/awake.53a8b14c-8811-11ed-ba42-321afeab1349.jpg\n",
      "3 data/images/awake.54505b0e-8811-11ed-ba42-321afeab1349.jpg\n",
      "4 data/images/awake.54f10ab8-8811-11ed-ba42-321afeab1349.jpg\n",
      "5 data/images/awake.5593d6b2-8811-11ed-ba42-321afeab1349.jpg\n",
      "6 data/images/awake.5634d86e-8811-11ed-ba42-321afeab1349.jpg\n",
      "7 data/images/awake.56d5e7c2-8811-11ed-ba42-321afeab1349.jpg\n",
      "8 data/images/awake.5779272a-8811-11ed-ba42-321afeab1349.jpg\n",
      "9 data/images/awake.581a8f7a-8811-11ed-ba42-321afeab1349.jpg\n",
      "10 data/images/awake.58bd5926-8811-11ed-ba42-321afeab1349.jpg\n",
      "11 data/images/awake.59601fb2-8811-11ed-ba42-321afeab1349.jpg\n",
      "12 data/images/awake.5a042274-8811-11ed-ba42-321afeab1349.jpg\n",
      "13 data/images/awake.5aa56f8a-8811-11ed-ba42-321afeab1349.jpg\n",
      "14 data/images/awake.5b476074-8811-11ed-ba42-321afeab1349.jpg\n",
      "15 data/images/awake.5be84d54-8811-11ed-ba42-321afeab1349.jpg\n",
      "16 data/images/awake.5c891f04-8811-11ed-ba42-321afeab1349.jpg\n",
      "17 data/images/awake.5d28ce46-8811-11ed-ba42-321afeab1349.jpg\n",
      "18 data/images/awake.5dcb644e-8811-11ed-ba42-321afeab1349.jpg\n",
      "19 data/images/awake.5e6ed19c-8811-11ed-ba42-321afeab1349.jpg\n",
      "Collecting images for drowsy\n",
      "0 data/images/drowsy.620d81ea-8811-11ed-ba42-321afeab1349.jpg\n",
      "1 data/images/drowsy.62af3c74-8811-11ed-ba42-321afeab1349.jpg\n",
      "2 data/images/drowsy.63524d92-8811-11ed-ba42-321afeab1349.jpg\n",
      "3 data/images/drowsy.63f50802-8811-11ed-ba42-321afeab1349.jpg\n",
      "4 data/images/drowsy.649838a6-8811-11ed-ba42-321afeab1349.jpg\n",
      "5 data/images/drowsy.653ab6bc-8811-11ed-ba42-321afeab1349.jpg\n",
      "6 data/images/drowsy.65de57ea-8811-11ed-ba42-321afeab1349.jpg\n",
      "7 data/images/drowsy.667f3656-8811-11ed-ba42-321afeab1349.jpg\n",
      "8 data/images/drowsy.671fd282-8811-11ed-ba42-321afeab1349.jpg\n",
      "9 data/images/drowsy.67c25372-8811-11ed-ba42-321afeab1349.jpg\n",
      "10 data/images/drowsy.6864e2cc-8811-11ed-ba42-321afeab1349.jpg\n",
      "11 data/images/drowsy.6908d738-8811-11ed-ba42-321afeab1349.jpg\n",
      "12 data/images/drowsy.69aaba1c-8811-11ed-ba42-321afeab1349.jpg\n",
      "13 data/images/drowsy.6a4cefc6-8811-11ed-ba42-321afeab1349.jpg\n",
      "14 data/images/drowsy.6aeff586-8811-11ed-ba42-321afeab1349.jpg\n",
      "15 data/images/drowsy.6b90710a-8811-11ed-ba42-321afeab1349.jpg\n",
      "16 data/images/drowsy.6c3671d6-8811-11ed-ba42-321afeab1349.jpg\n",
      "17 data/images/drowsy.6cd8d782-8811-11ed-ba42-321afeab1349.jpg\n",
      "18 data/images/drowsy.6d7cc3ba-8811-11ed-ba42-321afeab1349.jpg\n",
      "19 data/images/drowsy.6e1e6cb0-8811-11ed-ba42-321afeab1349.jpg\n"
     ]
    }
   ],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'images') # data/images\n",
    "labels = ['awake', 'drowsy']\n",
    "num_imgs = 20\n",
    "cap = cv.VideoCapture(0)\n",
    "for label in labels:\n",
    "    print(f\"Collecting images for {label}\")\n",
    "    time.sleep(5)\n",
    "    for img_num in range(num_imgs):\n",
    "        ret, frame = cap.read()\n",
    "        print(img_num, end=' ')\n",
    "        if ret:\n",
    "            cv.imshow('Camera', frame)\n",
    "            #New Path\n",
    "            imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1()) + '.jpg')\n",
    "            print(imgname)\n",
    "            # Writing out\n",
    "            cv.imwrite(imgname, frame)\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5210153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Practice.ipynb      \u001b[34myolov5\u001b[m\u001b[m/\r\n",
      "Yolo_Custom_Dataset.ipynb  yolov5m.pt\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/                      yolov5s.pt\r\n",
      "\u001b[34mruns\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd50f3a",
   "metadata": {},
   "source": [
    "### training??\n",
    "#### Enter the yolov5 directory (if u dont have it `git clone https://github.com/ultralytics/yolov5.git`)\n",
    "##### Create the custom yaml in visual studio code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0252933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/Users/adilbhatti/ComputerVision/train.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --img 320 --batch 16 --epochs 500 --data dataset.yaml --weights yolov5m.pt --workers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4506fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /Users/adilbhatti/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2022-12-30 Python-3.9.12 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20917590 parameters, 0 gradients, 48.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# thing = 'awake.54505b0e-8811-11ed-ba42-321afeab1349.jpg'\n",
    "# img = os.path.join('data', 'images', thing)\n",
    "# results = model(img)\n",
    "# old = cv.imread(img)\n",
    "# cv.imshow('pic', np.squeeze(results.render()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b65a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /Users/adilbhatti/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2023-2-2 Python-3.9.12 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20917590 parameters, 0 gradients, 48.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp7/weights/last.pt', force_reload = True)\n",
    "cap = cv.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = model(frame)\n",
    "        cv.imshow('YOLO', np.squeeze(results.render()))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d893789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
