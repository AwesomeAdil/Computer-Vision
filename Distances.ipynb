{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20341bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[93607]: Class CaptureDelegate is implemented in both /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x1696124d0) and /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x147d88860). One of the two will be used. Which one is undefined.\n",
      "objc[93607]: Class CVWindow is implemented in both /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x169612520) and /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1223aca68). One of the two will be used. Which one is undefined.\n",
      "objc[93607]: Class CVView is implemented in both /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x169612548) and /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1223aca90). One of the two will be used. Which one is undefined.\n",
      "objc[93607]: Class CVSlider is implemented in both /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x169612570) and /Users/adilbhatti/anaconda3/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1223acab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import uuid  # unique identifier\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8d335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adilbhatti/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adilbhatti/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /Users/adilbhatti/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\n",
    "midas.to('cpu')\n",
    "midas.eval()\n",
    "\n",
    "# Transforms\n",
    "transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\n",
    "transform = transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444d490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hands class\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# setting up hand functions\n",
    "hands = mp_hands.Hands(min_detection_confidence = 0.70)\n",
    "\n",
    "# drawing class\n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591ce228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns resulting image and results\n",
    "def detectHandLandmarks(img, hands, draw=True):\n",
    "    output_img = img.copy()\n",
    "    imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    \n",
    "    if results.multi_hand_landmarks and draw:\n",
    "        for hand_landmark in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(image = output_img, landmark_list = hand_landmark,\n",
    "                                      connections = mp_hands.HAND_CONNECTIONS,\n",
    "                                      landmark_drawing_spec = mp_draw.DrawingSpec(color=(0,0,255),\n",
    "                                                                                  thickness=5, circle_radius=5),\n",
    "                                      connection_drawing_spec=mp_draw.DrawingSpec(color = (0,0,0),\n",
    "                                                                                     thickness = 2, circle_radius = 10))\n",
    "    return (output_img, results)      \n",
    "\n",
    "# Text\n",
    "font                   = cv.FONT_HERSHEY_SIMPLEX\n",
    "fontScale              = 2\n",
    "fontColor              = (255,255,0)\n",
    "thickness              = 5\n",
    "lineType               = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4daf1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "rev_keys =     [['`', '1', '2', '3','4','5','6','7','8','9','0','-','=','delete'],\n",
    "            ['tab', 'q','w','e','r','t','y','u','i','o','p','[',']','\\\\'],\n",
    "            ['capslock','a','s','d','f','g','h','j','k','l',';',\"'\", 'return'],\n",
    "            ['shift', 'z','x','c','v','b','n','m',',','.','/','shift','shift']]\n",
    "\n",
    "keys = [layer[::-1] for layer in rev_keys]\n",
    "\n",
    "positions = []\n",
    "for j in range(4):\n",
    "    positions.append([])\n",
    "    for i in range(14 if j < 2 else 13):\n",
    "        px, py = 130 * i + 70 + 80*j,  290 + 165 * j\n",
    "        if j > 1:\n",
    "            px -= 45\n",
    "            py += 10\n",
    "        positions[-1].append((px,py))\n",
    "\n",
    "from itertools import chain\n",
    "flat_keys = list(chain.from_iterable(keys))\n",
    "flat_rev = list(chain.from_iterable(rev_keys))\n",
    "flat_pos = list(chain.from_iterable(positions))\n",
    "layout = {pos: key for pos, key in zip(flat_pos, flat_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26730f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "ptime = ctime = 0\n",
    "blank = np.zeros((1080, 1920, 3), np.uint8)\n",
    "\n",
    "dim = (1920, 1080)\n",
    "keyboard = cv.resize(cv.imread('Apple_Magic_Keyboard_-_US_remix_transparent.png'), dim, interpolation=cv.INTER_AREA)\n",
    "while cap.isOpened():\n",
    "    keyboard = cv.resize(cv.imread('Apple_Magic_Keyboard_-_US_remix_transparent.png'), dim, interpolation=cv.INTER_AREA)\n",
    "    hando = np.zeros((1080, 1920, 3), np.uint8)\n",
    "    ret, img = cap.read()\n",
    "    if not ctime:\n",
    "        h, w, c = img.shape\n",
    "    if ret:\n",
    "        rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        #imgbatch = transform(rgb).to('cpu')\n",
    "        \n",
    "#         with torch.inference_mode():\n",
    "#             pred = midas(imgbatch)\n",
    "#             pred = torch.nn.functional.interpolate(\n",
    "#                 pred.unsqueeze(1),\n",
    "#                 size=rgb.shape[:2],\n",
    "#                 mode = 'bicubic',\n",
    "#                 align_corners=False\n",
    "#             ).squeeze()\n",
    "#             dists = pred.cpu().numpy()\n",
    "#             comps = dists.copy()\n",
    "        \n",
    "        drawn_img, results = detectHandLandmarks(img, hands)\n",
    "        ctime = time.time()\n",
    "        fps = 1/(ctime-ptime)\n",
    "        ptime = ctime\n",
    "        result = hands.process(rgb)\n",
    "        cv.putText(img,f'FPS: {int(fps)}', (50, 70), font, fontScale,fontColor,thickness,lineType)\n",
    "        # Labeling the landmarks also calculates if thumbs is highest y coordinate\n",
    "        key = ''\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLms in results.multi_hand_landmarks:\n",
    "                qx, qy = handLms.landmark[6].x * w, handLms.landmark[6].y * h\n",
    "                px, py = handLms.landmark[8].x * w, handLms.landmark[8].y * h\n",
    "                wrist = (handLms.landmark[0].x * w, handLms.landmark[0].y * h)\n",
    "                anchor_point = (handLms.landmark[9].x * w, handLms.landmark[9].y * h)\n",
    "                basis = math.dist(anchor_point, wrist)\n",
    "                if(math.dist((0, py), (0, qy)) < 2*basis/5):  \n",
    "                    for pos, let in layout.items():\n",
    "                        if pos in positions[1] or pos in positions[2]:\n",
    "                            if math.dist(pos, (px+50, py)) < 50:\n",
    "                                key = let\n",
    "                                break\n",
    "                        elif pos in positions[0]:\n",
    "                            if math.dist(pos, (px-50, py)) < 50:\n",
    "                                key = let\n",
    "                                break\n",
    "                        else:\n",
    "                            if math.dist(pos, (px+150, py)) < 50:\n",
    "                                key = let\n",
    "                                break\n",
    "                \n",
    "                #cv.circle(blank,(int(px),int(py)), 20, (0,0,255), -1)\n",
    "                mp_draw.draw_landmarks(image = img, landmark_list = handLms,\n",
    "                                          connections = mp_hands.HAND_CONNECTIONS,\n",
    "                                          landmark_drawing_spec = mp_draw.DrawingSpec(color=(0,0,255),\n",
    "                                                                                      thickness=5, circle_radius=5),\n",
    "                                          connection_drawing_spec=mp_draw.DrawingSpec(color = (255,255,255),\n",
    "                                                                                         thickness = 10, circle_radius = 10))\n",
    "                mp_draw.draw_landmarks(image = hando, landmark_list = handLms,\n",
    "                                          connections = mp_hands.HAND_CONNECTIONS,\n",
    "                                          landmark_drawing_spec = mp_draw.DrawingSpec(color=(0,0,255),\n",
    "                                                                                      thickness=5, circle_radius=5),\n",
    "                                          connection_drawing_spec=mp_draw.DrawingSpec(color = (255,0,0),\n",
    "                                                                                         thickness = 10, circle_radius = 20))\n",
    "        else:\n",
    "            blank = np.zeros((1080, 1920, 3), np.uint8)\n",
    "        #dists *= (255.0/dists.max())\n",
    "        #cv.imshow('Dist', np.uint8(dists))\n",
    "        \n",
    "        hando = cv.flip(hando, 1)\n",
    "        edges = cv.Canny(keyboard, 100, 200)\n",
    "        over = cv.addWeighted(img,0.8,blank,1,0)\n",
    "        keylap = cv.addWeighted(img, 1, keyboard, 0.2,0)\n",
    "        keyboard = cv.addWeighted(keyboard, 0.2, hando, 1, 0)\n",
    "        cv.putText(keyboard,f'CLICK!{key}', (w - 350, 70), font, fontScale,fontColor,thickness,lineType)\n",
    "        for spot, let in zip(flat_pos, flat_rev):\n",
    "            cv.putText(keyboard,let, spot, font//2, fontScale,fontColor,thickness,lineType)\n",
    "            cv.circle(keyboard, spot, 50, (0,255,0), 1)\n",
    "        cv.imshow('Drawing', cv.flip(keylap, 1))\n",
    "        cv.imshow('Blank', cv.flip(over, 1))\n",
    "        cv.imshow('KEY', keyboard)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b266a56a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    cv.imshow(\"image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880214ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
