{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d78c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid  # unique identifier\n",
    "import os\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1358d",
   "metadata": {},
   "source": [
    "## Training from Scratch (simple object detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2818700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data_rps', 'images_rps') # data/images\n",
    "labels = ['Rock', 'Paper', 'Scissors', 'Lizard', 'Spock']\n",
    "num_imgs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48042fdd",
   "metadata": {},
   "source": [
    "### Collecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6168195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for Rock\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollecting images for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_imgs):\n\u001b[1;32m      6\u001b[0m         ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "for label in labels:\n",
    "    print(f\"Collecting images for {label}\")\n",
    "    time.sleep(5)\n",
    "    for img_num in range(num_imgs):\n",
    "        ret, frame = cap.read()\n",
    "        print(img_num, end=' ')\n",
    "        if ret:\n",
    "            cv.imshow('Camera', frame)\n",
    "            #New Path\n",
    "            imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1()) + '.jpg')\n",
    "            print(imgname)\n",
    "            # Writing out\n",
    "            cv.imwrite(imgname, frame)\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2df7d",
   "metadata": {},
   "source": [
    "### Create a new dataset!!! (use labelImg, .yaml file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py --img 320 --batch 16 --epochs 500 --data dataset.yaml --weights yolov5m.pt --workers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ff079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='runs/train/exp7/weights/last.pt', force_reload = True)\n",
    "cap = cv.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = model(frame)\n",
    "        cv.imshow('YOLO', np.squeeze(results.render()))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00e734",
   "metadata": {},
   "source": [
    "### Overcomplicating it with HandLandmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4395bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "cap = cv.VideoCapture(0)\n",
    "cTime = pTime = 0\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if ret:\n",
    "        h, w, c = img.shape\n",
    "        rbgimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        res = hands.process(rbgimg)\n",
    "        if res.multi_hand_landmarks:\n",
    "            for handLms in res.multi_hand_landmarks:\n",
    "                for i, lm in enumerate(handLms.landmark):\n",
    "                    cx = int(w * lm.x)\n",
    "                    cy = int(h * lm.y)\n",
    "                    if i and not i%4 :\n",
    "                        cv.circle(img, (cx, cy), 30, (0, 0, 255), -1)\n",
    "                rx = int(w * (handLms.landmark[5].x  + handLms.landmark[0].x) / 2)\n",
    "                ry = int(h * (handLms.landmark[5].y  + handLms.landmark[0].y) / 2)\n",
    "                cv.circle(img, (rx, ry), 150, (255, 255, 0), -1)\n",
    "                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime - pTime)\n",
    "        pTime = cTime\n",
    "        cv.putText(img, str(int(fps)), (10, 70), cv.FONT_HERSHEY_PLAIN, 3, (255, 255, 0), 3)\n",
    "        cv.imshow('Hands', img)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c12bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e128bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
